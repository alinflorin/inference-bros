name: Load testing LLM
run-name: Load-testing - ${{ github.event.inputs.location }} - ${{ github.event.inputs.model }} - ${{ github.run_id }}

on:
  workflow_dispatch:
    inputs:
      location:
        description: "Location for Bifrost"
        required: true
        type: choice
        options:
          - stalpeni
      concurrency:
        description: "Concurrency"
        required: false
        default: "2"
      requestCount:
        description: "Request Count"
        required: false
        default: "8"
      model:
        description: "LLM model name"
        required: false
        default: "kubeai/qwen25-05b-instruct"
      tokenizer:
        description: "LLM model tokenizer"
        required: false
        default: "Qwen/Qwen2.5-0.5B-Instruct"
env:
  PYTHON_VERSION: '3.12'
  AIPERF_VERSION: '0.5.0'

jobs:
  load-test:
    runs-on: ubuntu-latest
    name: Load testing

    steps:
      - uses: actions/setup-python@v6
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          
      - name: Cache Global Pip Tools
        uses: actions/cache@v5
        id: cache-global-tools
        with:
          path: ~/.local
          key: ${{ runner.os }}-global-aiperf-${{ env.AIPERF_VERSION }}

      - name: Cache Tokenizer
        uses: actions/cache@v5
        id: cache-tokenizer
        with:
          path: ~/.cache/huggingface/hub
          key: ${{ runner.os }}-tokenizer-${{ github.event.inputs.tokenizer }}
          restore-keys: |
            ${{ runner.os }}-tokenizer-

      - name: Add local bin to PATH
        run: echo "$HOME/.local/bin" >> $GITHUB_PATH

      - name: Install aiperf
        if: steps.cache-global-tools.outputs.cache-hit != 'true'
        run: pip install --user aiperf==${{ env.AIPERF_VERSION }}

      - name: Run benchmark
        run: aiperf profile --no-server-metrics --tokenizer ${{ github.event.inputs.tokenizer }} --ui-type none --api-key ${{ secrets.BIFROST_API_KEY }} --endpoint-type chat --endpoint /v1/chat/completions --request-count ${{ github.event.inputs.requestCount }} --concurrency ${{ github.event.inputs.concurrency }} --streaming --model ${{ github.event.inputs.model }} --url https://bifrost.${{ github.event.inputs.location }}.inferencebros.com

      - name: Upload Artifacts
        if: always()
        uses: actions/upload-artifact@v6
        with:
          name: aiperf-results-${{ github.run_id }}
          path: artifacts/